{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### This program requires a local installation of APACHE SPARK to run\n",
    "# Writing csv to Postgres/AWS Server\n",
    "\n",
    "# import libraries\n",
    "import findspark\n",
    "\n",
    "# Start Spark Session\n",
    "findspark.init('C:\\Spark\\spark-3.2.2-bin-hadoop2.7')\n",
    "import pyspark\n",
    "from pyspark import SparkFiles\n",
    "from pyspark.sql.functions import to_date, to_timestamp\n",
    "from getpass import getpass\n",
    "\n",
    "\n",
    "# Build Spark Session\n",
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder.appName(\"Qwest-Analytics-Dashboard-and-ML-Model\").config(\"spark.jars\", \"C:\\Spark\\spark-3.2.2-bin-hadoop2.7\\jars\\postgresql-42.5.0.jar\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Spark\\spark-3.2.2-bin-hadoop2.7\\python\\pyspark\\sql\\context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('spark.app.name', 'Qwest-Analytics-Dashboard-and-ML-Model'),\n",
       " ('spark.app.initial.jar.urls',\n",
       "  'spark://10.0.0.190:49213/jars/postgresql-42.5.0.jar'),\n",
       " ('spark.driver.host', '10.0.0.190'),\n",
       " ('spark.repl.local.jars',\n",
       "  'file:///C:/Spark/spark-3.2.2-bin-hadoop2.7/jars/postgresql-42.5.0.jar'),\n",
       " ('spark.executor.id', 'driver'),\n",
       " ('spark.jars',\n",
       "  'C:\\\\Spark\\\\spark-3.2.2-bin-hadoop2.7\\\\jars\\\\postgresql-42.5.0.jar'),\n",
       " ('spark.driver.memory', '16g'),\n",
       " ('spark.app.startTime', '1668733532559'),\n",
       " ('spark.rdd.compress', 'True'),\n",
       " ('spark.serializer.objectStreamReset', '100'),\n",
       " ('spark.sql.warehouse.dir',\n",
       "  'file:/F:/Data%20Analytics/Final%20Project/Test%20Code/spark-warehouse'),\n",
       " ('spark.master', 'local[*]'),\n",
       " ('spark.submit.pyFiles', ''),\n",
       " ('spark.submit.deployMode', 'client'),\n",
       " ('spark.app.id', 'local-1668733533607'),\n",
       " ('spark.ui.showConsoleProgress', 'true'),\n",
       " ('spark.driver.port', '49213')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "sc=spark.sparkContext\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "spark.sparkContext._conf.getAll()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------+--------------+------------------------------+--------+-----------+------------------+--------------------+------+\n",
      "|               time|    country|total_sessions|total_session_duration_seconds|operator|    channel|cleaned_content_id|               genre|region|\n",
      "+-------------------+-----------+--------------+------------------------------+--------+-----------+------------------+--------------------+------+\n",
      "|2021-02-16 00:57:00|    Finland|           1.0|                          20.0|  Op_001|Channel_002|          PRO_1301|   OPERA , CLASSICAL|Europe|\n",
      "|2021-02-16 01:22:00|    Morocco|           1.0|                          13.0|  Op_001|Channel_002|          PRO_1326|ORCHESTRA, CLASSI...|Africa|\n",
      "|2021-02-16 05:03:00|    Germany|           1.0|                           2.0|  Op_001|Channel_002|          PRO_1355|ROMANTIC, CHAMBER...|Europe|\n",
      "|2021-02-16 14:03:00|      Italy|           1.0|                          29.0|  Op_001|Channel_002|          PRO_1293|    OPERA , ROMANTIC|Europe|\n",
      "|2021-02-16 15:28:00|    Morocco|           1.0|                          44.0|  Op_001|Channel_002|          PRO_1351|ORCHESTRA, 20TH C...|Africa|\n",
      "|2021-02-16 19:02:00|    Germany|           1.0|                           2.0|  Op_001|Channel_002|          PRO_1383|DANCE, CONTEMPORA...|Europe|\n",
      "|2021-02-16 20:17:00|    Finland|           1.0|                          19.0|  Op_001|Channel_002|          PRO_1383|DANCE, CONTEMPORA...|Europe|\n",
      "|2021-02-16 22:23:00|    Morocco|           1.0|                          44.0|  Op_001|Channel_002|          PRO_1326|ORCHESTRA, CLASSI...|Africa|\n",
      "|2021-02-16 23:40:00|     Sweden|           1.0|                           5.0|  Op_001|Channel_002|          PRO_1380|CLASSICAL, DANCE,...|Europe|\n",
      "|2021-02-16 00:00:00|South Korea|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:00:00|      India|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:01:00|      India|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:01:00|South Korea|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:02:00|South Korea|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:02:00|      India|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:03:00|South Korea|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:03:00|      India|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:04:00|South Korea|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:04:00|      India|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "|2021-02-16 00:05:00|South Korea|           1.0|                          60.0|  Op_002|Channel_002|           PRO_327|VOCAL JAZZ, GOSPE...|  Asia|\n",
      "+-------------------+-----------+--------------+------------------------------+--------+-----------+------------------+--------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Import table into Spark Instance\n",
    "resources_path = 'F:/Data Analytics/Final Project/Resources/'\n",
    "\n",
    "cleaned_minute_aggregation_df = spark.read.csv(SparkFiles.get(f'{resources_path}cleaned_merged_minute_aggregate_data-2022-11-17.csv'), sep=',', header=True)\n",
    "# Drop index column\n",
    "cleaned_minute_aggregation_df = cleaned_minute_aggregation_df.drop('_c0')\n",
    "cleaned_minute_aggregation_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: string (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- total_sessions: string (nullable = true)\n",
      " |-- total_session_duration_seconds: string (nullable = true)\n",
      " |-- operator: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- cleaned_content_id: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_minute_aggregation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert time column to datetime and total_sessions and total_sessions_duration_seconds to float\n",
    "cleaned_minute_aggregation_df = cleaned_minute_aggregation_df.withColumn('time', to_timestamp('time'))\n",
    "cleaned_minute_aggregation_df = cleaned_minute_aggregation_df.withColumn('total_sessions', cleaned_minute_aggregation_df.total_sessions.cast('double'))\n",
    "cleaned_minute_aggregation_df = cleaned_minute_aggregation_df.withColumn('total_session_duration_seconds', cleaned_minute_aggregation_df.total_session_duration_seconds.cast('double'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- time: timestamp (nullable = true)\n",
      " |-- country: string (nullable = true)\n",
      " |-- total_sessions: double (nullable = true)\n",
      " |-- total_session_duration_seconds: double (nullable = true)\n",
      " |-- operator: string (nullable = true)\n",
      " |-- channel: string (nullable = true)\n",
      " |-- cleaned_content_id: string (nullable = true)\n",
      " |-- genre: string (nullable = true)\n",
      " |-- region: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cleaned_minute_aggregation_df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connecting to database and exporting data\n",
    "\n",
    "#Store environmental variables\n",
    "password = getpass('Enter DataBase Password: ')\n",
    "\n",
    "#Configure for RDS\n",
    "mode = 'append'\n",
    "jdbc_url=\"jdbc:postgresql://qwest-final-project.ccngkdwtiuvz.us-east-2.rds.amazonaws.com:5432/Qwest-Database\"\n",
    "config = {\"user\":\"postgres\", \n",
    "          \"password\": password, \n",
    "          \"driver\":\"org.postgresql.Driver\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WRITE TABLES TO DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import table into Spark Instance\n",
    "clean_viewership_df = spark.read.csv(SparkFiles.get(f'{resources_path}Cleaned_Viewership_Data_v4.csv'), sep=',', header=True)\n",
    "clean_viewership_df.write.jdbc(url=jdbc_url, table = 'cleaned_viewership_data', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import table into Spark Instance\n",
    "clean_advertising_df = spark.read.csv(SparkFiles.get(f'{resources_path}Clean_Advertising_Data_v4.csv'), sep=',', header=True)\n",
    "clean_advertising_df.write.jdbc(url=jdbc_url, table = 'cleaned_advertising_data', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write Cleaned_Merged_Minute_Aggregation to table in RDS\n",
    "cleaned_minute_aggregation_df.write.jdbc(url=jdbc_url, table = 'cleaned_merged_minute_aggregation', mode=mode, properties=config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CHECK IF TABLES ARE READABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if you can import\n",
    "minute_aggregation_test_df = spark.read.format(\"jdbc\").options(\n",
    "         url='jdbc:postgresql://qwest-final-project.ccngkdwtiuvz.us-east-2.rds.amazonaws.com:5432/Qwest-Database',\n",
    "         dbtable='cleaned_merged_minute_aggregation',\n",
    "         user='postgres',\n",
    "         password=password,\n",
    "         driver='org.postgresql.Driver').load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------+--------------+------------------------------+-----------+--------+------------------+-------------------+\n",
      "|               time|      country|total_sessions|total_session_duration_seconds|    channel|operator|cleaned_content_id|              genre|\n",
      "+-------------------+-------------+--------------+------------------------------+-----------+--------+------------------+-------------------+\n",
      "|2022-05-10 19:57:00|United States|          79.0|                        4276.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 19:57:00|  Puerto Rico|           3.0|                          30.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 19:57:00|       Canada|           1.0|                          60.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 19:58:00|United States|          89.0|                        4337.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 19:58:00|       Canada|           1.0|                          60.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 19:59:00|       Mexico|           2.0|                          53.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 19:59:00|United States|          78.0|                         801.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 19:59:00|       Canada|           2.0|                          23.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:00:00|  Puerto Rico|           1.0|                          37.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:00:00|       Canada|           1.0|                          60.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:00:00|United States|          77.0|                        4145.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:01:00|       Canada|           1.0|                          60.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:01:00|     Honduras|           1.0|                          79.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:01:00|       Mexico|           3.0|                          62.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:01:00|United States|          91.0|                        4624.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:02:00|  Puerto Rico|           1.0|                          54.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:02:00|       Canada|           1.0|                          60.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:02:00|United States|          82.0|                        4137.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:03:00|       Canada|           1.0|                          60.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "|2022-05-10 20:03:00|United States|          82.0|                        4435.0|Channel_002|  Op_009|          PRO_1759|ROMANTIC, ORCHESTRA|\n",
      "+-------------------+-------------+--------------+------------------------------+-----------+--------+------------------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "minute_aggregation_test_df.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('ML-GPU')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "448edaee4350f241a20dd5523d676348370318c49887029613f9e42feaa6bcd3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
